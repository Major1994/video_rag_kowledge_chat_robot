# inverted_index_tfidf.py

import jieba
import math
from collections import defaultdict

# ================================
# 1. ç¤ºä¾‹æ–‡æ¡£æ•°æ®
# ================================
documents = {
    "doc1": "çŒ«å–œæ¬¢ç©è€ï¼Œç‰¹åˆ«çˆ±æŠ“è€é¼ ",
    "doc2": "ç‹—å–œæ¬¢è·‘æ­¥ï¼Œéå¸¸å¿ è¯š",
    "doc3": "çŒ«å’Œç‹—éƒ½æ˜¯å¯çˆ±çš„å® ç‰©",
    "doc4": "å¤§å®¶éƒ½çˆ±å¯çˆ±çš„åŠ¨ç‰©"
}

# ================================
# 2. åœç”¨è¯è¡¨
# ================================
stop_words = {
    'çš„', 'äº†', 'å’Œ', 'éƒ½', 'æ˜¯', 'åœ¨', 'æœ‰', 'è¿™', 'é‚£', 'å°±',
    'ä¹Ÿ', 'å¾ˆ', 'å¤ª', 'åˆ', 'ä¸', 'ä½†', 'åª', 'è¦', 'ä¼š', 'å¯ä»¥',
    'èƒ½å¤Ÿ', 'åº”è¯¥', 'ä¸€ä¸ª', 'ä¸€äº›', 'è¿™ç§', 'é‚£ç§', 'æˆ‘ä»¬', 'ä½ ä»¬',
    'ä»–ä»¬', 'å¥¹', 'ä»–', 'å®ƒ', 'æˆ‘', 'ä½ ', 'ç€', 'è¿‡', 'å¾—', 'åœ°', 'å—', 'å‘¢', 'å§', 'å•Š'
}

# ================================
# 3. æ„å»ºå€’æ’ç´¢å¼• + è¯é¢‘ç»Ÿè®¡ï¼ˆTFï¼‰
# ================================
inverted_index = defaultdict(set)
term_freq = defaultdict(dict)  # term_freq[doc_id][word] = é¢‘æ¬¡
doc_lengths = {}  # æ¯ä¸ªæ–‡æ¡£çš„æœ‰æ•ˆè¯æ•°ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰

print("ğŸ” åˆ†è¯ä¸è¯é¢‘ç»Ÿè®¡ï¼ˆè¿‡æ»¤åœç”¨è¯ï¼‰ï¼š")
for doc_id, content in documents.items():
    words = list(jieba.cut_for_search(content))
    filtered_words = []
    word_count = defaultdict(int)
    
    for word in words:
        word = word.strip()
        if not word or word in stop_words:
            continue
        filtered_words.append(word)
        word_count[word] += 1
    
    # ä¿å­˜è¯é¢‘
    for word, freq in word_count.items():
        inverted_index[word].add(doc_id)
        term_freq[doc_id][word] = freq
    
    doc_lengths[doc_id] = len(filtered_words)
    print(f"{doc_id}: {filtered_words} (å…± {len(filtered_words)} è¯)")

# æ€»æ–‡æ¡£æ•°
N = len(documents)
print(f"\nğŸ“Š æ€»æ–‡æ¡£æ•°: {N}")

# ================================
# 4. è®¡ç®— IDF
# ================================
def compute_idf(word, index, total_docs):
    """è®¡ç®— IDF = log(N / df)"""
    df = len(index.get(word, set()))  # åŒ…å«è¯¥è¯çš„æ–‡æ¡£æ•°
    if df == 0:
        return 0
    return math.log(total_docs / df)

# ç¼“å­˜ IDF å€¼
idf_values = {}

# ================================
# 5. TF-IDF æœç´¢ä¸æ’åº
# ================================
def search_tfidf(query_text, index, term_freq, doc_lengths, stop_words_set, documents_dict):
    """æœç´¢å¹¶æŒ‰ TF-IDF ç›¸å…³æ€§æ’åº"""
    words = list(jieba.cut_for_search(query_text))
    query_words = [w.strip() for w in words if w.strip() and w not in stop_words_set]
    
    if not query_words:
        return []
    
    print(f"ğŸ” å®é™…æŸ¥è¯¢è¯: {query_words}")
    
    scores = defaultdict(float)
    
    for word in query_words:
        if word not in index:
            continue
        # è®¡ç®— IDF
        if word not in idf_values:
            idf_values[word] = compute_idf(word, index, N)
        idf = idf_values[word]
        
        # å¯¹æ¯ä¸ªåŒ…å«è¯¥è¯çš„æ–‡æ¡£è®¡ç®— TF-IDF
        for doc_id in index[word]:
            tf = term_freq[doc_id].get(word, 0)
            # TF å½’ä¸€åŒ–ï¼štf / doc_length
            tf_norm = tf / doc_lengths[doc_id] if doc_lengths[doc_id] > 0 else 0
            # ç´¯åŠ  TF-IDF åˆ†æ•°ï¼ˆå¤šä¸ªæŸ¥è¯¢è¯ï¼‰
            scores[doc_id] += tf_norm * idf
    
    # æŒ‰åˆ†æ•°é™åºæ’åº
    ranked_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    # è¿”å› (doc_id, score, content)
    return [(doc_id, score, documents_dict[doc_id]) for doc_id, score in ranked_results]

# ================================
# 6. æµ‹è¯•æŸ¥è¯¢
# ================================
print("\nğŸ” TF-IDF æœç´¢æµ‹è¯•ï¼š")

# ç¤ºä¾‹1ï¼šæœç´¢â€œçŒ« çˆ±â€
results = search_tfidf("çŒ« çˆ±", inverted_index, term_freq, doc_lengths, stop_words, documents)
print("\n--- æœç´¢ 'çŒ« çˆ±' ---")
for i, (doc_id, score, content) in enumerate(results, 1):
    print(f"{i}. [{doc_id}] åˆ†æ•°: {score:.4f} | å†…å®¹: {content}")

# ç¤ºä¾‹2ï¼šæœç´¢â€œå¯çˆ± åŠ¨ç‰©â€
results2 = search_tfidf("å¯çˆ± åŠ¨ç‰©", inverted_index, term_freq, doc_lengths, stop_words, documents)
print("\n--- æœç´¢ 'å¯çˆ± åŠ¨ç‰©' ---")
for i, (doc_id, score, content) in enumerate(results2, 1):
    print(f"{i}. [{doc_id}] åˆ†æ•°: {score:.4f} | å†…å®¹: {content}")

# ç¤ºä¾‹3ï¼šå•ä¸ªè¯
results3 = search_tfidf("å¿ è¯š", inverted_index, term_freq, doc_lengths, stop_words, documents)
print("\n--- æœç´¢ 'å¿ è¯š' ---")
for i, (doc_id, score, content) in enumerate(results3, 1):
    print(f"{i}. [{doc_id}] åˆ†æ•°: {score:.4f} | å†…å®¹: {content}")